---
title:  
layout: single
permalink: /tutorials/program/
sidebar: 
    nav: "tutorials"
toc: true
toc_sticky: true
toc_icon: "cog"
---
## Tutorial Details

The following tutorials have been accepted for ACL-IJCNLP 2021 and will be held on Sunday, August 1st, 2021. 
		
### T1: Advances in Debating Technologies: Building AI That Can Debate Humans

Pre-recorded lecture<br/>
Live Q&A, 2021-08-01 13:00&ndash;14:00 (UTC)<br/>
*Organizers: Roy Bar-Haim, Liat Ein-Dor, Matan Orbach, Elad Venezian and Noam Slonim*

![t1](/assets/images/t1.png)

The tutorial focuses on Debating Technologies, a sub-field of computational argumentation defined as “computational technologies developed directly to enhance, support, and engage with human debating” (Gurevych et al., 2016). A recent milestone in this field is Project Debater, which was revealed in 2019 as the first AI system that can debate human experts on complex topics. Project Debater is the third in the series of IBM Research AI’s grand challenges, following Deep Blue and Watson. It has been developed for over six years by a large team of researchers and engineers, and its live demonstration in February 2019 received massive media attention. This research effort has resulted in more than 50 scientific papers to date, and many datasets freely available for research purposes. We discuss the scientific challenges that arise when building such a system, including argument mining, argument quality assessment, stance classification, principled argument detection, narrative generation, and rebutting a human opponent. Many of the underlying capabilities of Project Debater have been made freely available for academic research, and the tutorial will include a detailed explanation of how to use and leverage these tools. In addition to discussing individual components, the tutorial also provides a holistic view of a debating system. Such a view is largely missing in the academic literature, where each paper typically addresses a specific problem in isolation. We present a complete pipeline of a debating system, and discuss the information flow and the interaction between the various components. Finally, we discuss practical applications and future challenges of debating technologies.

### T2: Event-Centric Natural Language Understanding

Live, 2021-07-31 23:00 to 2021-08-01 3:00 (UTC)<br/>
*Instructors: Muhao Chen, Hongming Zhang, Qiang Ning, Manling Li, Heng Ji, Kathleen McKeown and Dan Roth*

![t2](/assets/images/t2.png)   

This tutorial targets researchers and practitioners who are interested in AI technologies that help machines understand natural language text, particularly real-world events described in the text. These include methods to extract the internal structures of an event regarding its protagonist(s), participant(s) and properties, as well as external structures concerning memberships, temporal and causal relations of multiple events. This tutorial will provide audience with a systematic introduction of (i) knowledge representations of events, (ii) various methods for automated extraction, conceptualization and prediction of events and their relations, (iii) induction of event processes and properties, and (iv) a wide range of NLU and commonsense understanding tasks that benefit from aforementioned techniques. We will conclude the tutorial by outlining emerging research problems in this area.

### T3: Meta Learning and Its Applications to Natural Language Processing

Live, 2021-08-01 13:00&ndash;17:00 (UTC)<br/>
*Instructors: Hung-yi Lee, Ngoc Thang Vu, Shang-Wen Li*

![t3](/assets/images/t3.png)    

Deep learning based natural language processing (NLP) has become the mainstream of research in recent years and significantly outperforms conventional methods. However, deep learning models are notorious for being data and computation hungry. These downsides limit the application of such models from deployment to different domains, languages, countries, or styles, since collecting in-genre data and model training from scratch are costly. The long-tail nature of human language makes challenges even more significant. 

Meta-learning, or ‘Learning to Learn’, aims to learn better learning algorithms, including better parameter initialization, optimization strategy, network architecture, distance metrics, and beyond. Meta-learning has been shown to allow faster fine-tuning, converge to better performance, and achieve amazing results for few-shot learning in many applications. 
Meta-learning is one of the most important new techniques in machine learning in recent years. There is a related tutorial in ICML 2019 and a related course at Stanford, but most of the example applications given in these materials are about image processing. It is believed that meta-learning has great potential to be applied in NLP, and some works have been proposed with notable achievements in several relevant problems, e.g., relation extraction, machine translation, and dialogue generation and state tracking. However, it does not catch the same level of attention as in the image processing community. 

In the tutorial, we will first introduce Meta-learning approaches and the theory behind them, and then review the works of applying this technology to NLP problems. This tutorial intends to facilitate researchers in the NLP community to understand this new technology better and promote more research studies using this new technology.

### T4: Pre-training Methods for Neural Machine Translation

Pre-recorded lecture<br/>
Live Q&A, 2021-08-01 2:00&ndash;3:00 (UTC)<br/>
Live Q&A, 2021-08-01 13:00&ndash;14:00 (UTC)<br/>
*Instructors: Mingxuan Wang, Lei Li* 

![t4](/assets/images/t4.png)  

This tutorial provides a comprehensive guide to make the most of pre-training for neural machine translation. 
Firstly, we will briefly introduce the background of NMT, pre-training methodology, and point out the main challenges when applying pre-training for NMT.  Then we will focus on analysing the role of pre-training  in enhancing the performance of NMT,  how to design a better pre-training model for executing specific NMT tasks and how to better integrate the pre-trained model into NMT system.  In each part, we will provide examples, discuss training techniques and analyse what is transferred when applying pre-training.

### T5: Prosody: Models, Methods, and Applications

Live, 2021-07-31 23:00 to 2021-08-01 3:00 (UTC)<br/>
Live, 2021-08-01 13:00 to 17:00 (UTC)<br/>
*Instructors: Nigel Ward, Gina-Anne Levow* 

![t5](/assets/images/t5.png)  

Prosody is essential in human interaction, enabling people  to  show  interest,  establish  rapport,  efficiently convey nuances of attitude or intent, and so  on.   Some  applications  that  exploit  prosodic knowledge have recently shown superhuman performance, and in many respects our ability to effectively model prosody is rapidly advancing. This tutorial will overview the computational modeling of prosody, including recent advances and diverse actual and potential applications.

### T6: Recognizing Multimodal Entailment

Live, 2021-08-01 13:00&ndash;17:00 (UTC)<br/>
*Instructors: Cesar Ilharco, Afsaneh Shirazi, Arjun Gopalan, Arsha Nagrani, Blaz Bratanic, Christina Funk, Felipe Ferreira, Gabriel Barcik, Jannis Bulian, Jared Frank, Lucas Smaira, Qin Cao, Ricardo Marino, Roma Patel*

![t6](/assets/images/t6.png)        

How information is created, shared and consumed has changed rapidly in recent decades, in part thanks to new social platforms and technologies on the web. With ever-larger amounts of unstructured and limited labels, organizing and reconciling information from different sources and modalities is a central challenge in machine learning.

This cutting-edge tutorial aims to introduce the multimodal entailment task, which can be useful for detecting semantic alignments when a single modality alone does not suffice for a whole content understanding. Starting with a brief overview of natural language processing, computer vision, structured data and neural graph learning, we lay the foundations for the multimodal sections to follow. We then discuss recent multimodal learning literature covering visual, audio and language streams, and explore case studies focusing on tasks which require fine-grained understanding of visual and linguistic semantics question answering, veracity and hatred classification. Finally, we introduce a new dataset for recognizing multimodal entailment, exploring it in a hands-on collaborative section. 

Overall, this tutorial gives an overview of multimodal learning, introduces a multimodal entailment dataset, and encourages future research in the topic.

